一致性非锁定读，也叫快照读：（MVCC实现，而MVCC基于undo log）
当session A读取的行正在session B事务内执行DELETE、UPDATE操作时（此时session B 对数据行加了X锁），这时session A的读取操作不会因此等待行上
的锁释放。相反，它会去读取一个数据快照。（而在RR隔离级别下，session B提交了事务，释放了锁后，session A读取的仍是 session A事务开始时的
数据版本。而在RC隔离级别下，sessionB提交了事务，释放了锁后，session A读取的是数据最新版本，是被session B修改后的版本。此时对于session A
来说，是不可重复读）现在相信大家已经理解了我们为什么将它称之为非锁定读，因为不需要等待访问行上X锁的释放。

             Session A              Session B

           SET autocommit=0;      SET autocommit=0;
time
|          SELECT * FROM t;
|          empty set
|                                 INSERT INTO t VALUES (1, 2);
|
v          SELECT * FROM t;
           empty set
                                  COMMIT;

           SELECT * FROM t;
           empty set

           COMMIT;

           SELECT * FROM t;
           ---------------------
           |    1    |    2    |
           ---------------------


innodb在默认情况下的读采取的是一致性非锁定读，但在某些情况下，innodb不采用这种方法。
比如，你在显式对读进行加锁情况下（当前读）
select * from table where ? lock in share mode;(sets an IS lock)
select * from table where ? for update;(sets an IX lock)
或者在外键的插入和更新上，因为在外键的插入更新上，对于数据的隔离性要求较高，在插入前需要扫描父表中的记录是否存在，
所以，innodb在外键添加删除这种操作上，会采用加S锁的这种方式来实现。

rc事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据.（因为read commited嘛，但不可重复读）
RR事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。

注意：快照读只适用于SELECT语句，不适用与DML语句（DML语句是当前读），所以事务中的DML语句（当前读）是可以看到其他session中的事务的更新的，即时SELECT并不能看到这些


快照读：就是select
select * from table ....;
当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。
select * from table where ? lock in share mode;(sets an IS lock)
select * from table where ? for update;(sets an IX lock)
insert;
update ? where ?;
delete ? where ?;
事务的隔离级别实际上都是定义了当前读的级别

--------------------------------------------------------------------------------------------------------------
事务和锁

所谓innodb行锁，是针对有索引的语句，如果语句没有使用上索引，那么就会变成无索引退化，对于当前读就会变成表锁。


对于当前读：
序列化
幻读（如果只有幻读，那么就已经可重复读）
可重复读
不可重复读
脏读


autocommit = 1，使每一个语句都成为一个事务。If a statement returns an error, the commit or rollback behavior depends on the error：
http://dev.mysql.com/doc/refman/5.6/en/innodb-transaction-model.html
autocommit = 0, commit或者rollback后，会自动又开启一个事务，就是说当前session始终有事务打开

自动提交情况下，如果想用多条语句事务，可以使用 start transaction 或者 begin 结束时或者commit或者rollback。
commit和rollback会释放当前session持有的所有锁



事务隔离级别（要从当前事务和其他事务两个角度考虑，而且要有时序图与锁的想象，因为隔离级别通过锁实现）：

SERIALIZABLE        从MVCC退化为基于锁的并发控制。无快照读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。读写互斥。
READ UNCOMMITTED    可读未提交，会脏读，不可重复读，会幻读
READ COMMITTED      未提交不可读，只能读已提交。不会脏读，不可重复读，会幻读
REPEATABLE READ     可重复读，需要用next-key解决幻读
                    REPEATABLE READ, enables higher concurrency by allowing transactions to read rows that have exclusive locks,
                    a technique known as consistent nonlocking read.






锁：
record lock
gap lock
next key lock
行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别的幻读问题。

共享锁  也叫S锁  也叫读锁
排他锁  也叫X锁  也叫写锁
意向锁  包括IS锁与IX锁


    	 X          IX	         S      	   IS
X	  Conflict	Conflict	  Conflict	  Conflict
IX	Conflict	Compatible	Conflict	  Compatible
S	  Conflict	Conflict	  Compatible	Compatible
IS	Conflict	Compatible	Compatible	Compatible


死锁：
innodb_print_all_deadlocks：
When this option is enabled, information about all deadlocks in InnoDB user transactions is recorded in the mysqld error log.
Otherwise, you see information about only the last deadlock, using the SHOW ENGINE INNODB STATUS command. 

-----------------------------------------------------------
锁等待，锁排队，锁超时：

information_schema库的innodb_lock_waits表	
锁等待的对应关系，字段说明：
requesting_trx_id 请求锁的事务ID
requested_lock_id 请求锁的锁ID
blocking_trx_id 当前拥有锁的事务ID
blocking_lock_id 当前拥有锁的锁ID

information_schema库的四个表
INNODB_TRX
INNODB_LOCKS
INNODB_LOCK_WAITS	
processlist显示事务、事务持有/等待的锁。对于诊断锁等待、长事务很重要。


Innodb行锁等待超时参数 innodb_lock_wait_timeout

-------------------------------------------------------------------------------------------------------
加锁语句：
因为事务一旦完成（commit或者rollback），事务所持有的锁就会释放。
故在autocommit = 1 时，需要注意

select * from table where ? lock in share mode;(sets an IS lock)
select * from table where ? for update;(sets an IX lock)
当autocommit 系统变量值为off 或者为0 时可直接使用不用手动的begin or start transaction开启事务，
如果autocommit为1，需要begin或者start transaction 在使用上述两个语句加锁（因为如果为1，自动提交，事务就结束了，锁就释放了嘛）
表的引擎需要支持事务，比如INNODB。



加表锁：
The correct way to use LOCK TABLES with transactional tables, such as InnoDB tables, is to begin a transaction 
with SET autocommit = 0(not START TRANSACTION) followed by LOCK TABLES, and to not call UNLOCK TABLES until 
you commit the transaction explicitly. 
如下：
SET autocommit=0;
LOCK TABLES t1 WRITE, t2 READ, ...;
... do something with tables t1 and t2 here ...
COMMIT;
UNLOCK TABLES;

加表锁语句：
LOCK TABLES ... WRITE 表写锁
LOCK TABLES ... READ  表读锁

---------------------------------------------------
加全局读锁（xtrabackup备份时，copy完ibd文件会使用），
FLUSH TABLES WITH READ LOCK(UNLOCK TABLES 配合使用）：FLUSH TABLES WITH READ LOCK后一定要UNLOCK TABLES，除非你想让系统只读！

作用：
Closes all open tables and locks all tables for all databases with a read lock until you explicitly release the lock 
by executing UNLOCK TABLES. 

实现过程：
1，set the global read lock - after this step, insert/update/delete/replace/alter statements cannot run
2，close open tables - this step will block until all statements started previously have stopped
3，set a flag to block commits

备份时的作用：（为了避免FTWRL的影响，所以一般在备库做备份）
FTWRL的3个步骤：
1. 上全局读锁
2. 清理表缓存
3. 上全局COMMIT锁
第一步的作用是堵塞更新，备份时，我们期望获取此时数据库的一致状态，不希望有更多的更新操作进来。对于innodb引擎而言，其自身的MVCC机制，
可以保证读到老版本数据，因此第一步对它使多余的。
第二步，清理表缓存，这个操作对于myisam有意义，关闭myisam表时，会强制要求表的缓存落盘，这对于物理备份myisam表是有意义的，
因为物理备份是直接拷贝物理文件。对于innodb表，则无需这样，因为innodb有自己的redolog，只要记录当时LSN，然后备份LSN以后的redolog即可。
第三步，主要是保证能获取一致性的binlog位点，这点对于myisam和innodb作用是一样的。

小技巧：
在手动做FLUSH TABLES WITH READ LOCK/set global read_only=1之前，先执行一下FLUSH TABLES，能够很大概率地减小系统变成只读的时间

其他：
“set global read_only=1”这个命令实际上也和FTWRL类似，也需要上两把MDL，只是不需要清理表缓存而已。如果老主库上还有大的更新事务，
将导致set global read_only hang住，设置失败。因此切换程序在设计时，要考虑这一点。


疑问：
因为FTWRL是要flush脏页的，只有这样才真的能保证数据一致性(比如说在xtrabackup备份myisam表的时候)，而在select count(*) from tb执行的时候，
因为所有的操作都是在内存中操作，所以此时还不能完全flush，因此FTWRL就得等待。（是这样吗？就是刷新表的那一步？）


-----------------------------------------------------------------------------------------------------
相关参数
innodb_lock_wait_timeout

---------------------------------------------------------------------------------------------------------
逻辑概念：

undo log   保证事务的原子性（就是说得有一个地方记录回滚的数据），以及用来实现MVCC（因为记录了可以用来回滚的数据，所有数据的历史版本）

redo log   保证事务的持久性（日志先行）




物理文件相关：

ibdata file                              
系统表空间

.ibd file
表独立表空间
.frm
mysql层表定义文件

     
ib_logfile0，ib_logfile1  存有redo log


system tablespace
One or more data files (ibdata files) containing the metadata for InnoDB-related objects (the data dictionary), and the storage areas
for one or more undo logs, the change buffer, and the doublewrite buffer. Depending on the setting of the innodb_file_per_table,
when tables are created, it might also contain table and index data for some or all InnoDB tables. The data and metadata in the 
system tablespace apply to all the databases in a MySQL instance.
Prior to MySQL 5.6.7, the default was to keep all InnoDB tables and indexes inside the system tablespace, often causing this file 
to become very large. Because the system tablespace never shrinks, storage problems could arise if large amounts of temporary data
were loaded and then deleted. In MySQL 5.6.7 and higher, the default is file-per-table mode, where each table and its associated
indexes are stored in a separate .ibd file. This new default makes it easier to use InnoDB features that rely on the Barracuda file 
format, such as table compression, off-page storage for long variable-length column values, and large index key
prefixes (innodb_large_prefix).
Keeping all table data in the system tablespace or in separate .ibd files has implications for storage management in general. 
The MySQL Enterprise Backup product might back up a small set of large files, or many smaller files. On systems with thousands of 
tables, the file system operations to process thousands of .ibd files can cause bottlenecks.
In MySQL 5.6 and higher, the innodb_undo_tablespaces option allows you to configure separate tablespace files for undo logs. 
These files are still considered part of the system tablespace.



data dictionary
Metadata that keeps track of InnoDB-related objects such as tables, indexes, and table columns. This metadata is physically located 
in the InnoDB system tablespace. For historical reasons, it overlaps to some degree with information stored in the .frm files.


--------------------------------------------------------------------------------------------------------------------
代码细节：

崩溃恢复，undo，redo，checkpoint，lsn，xa，binlog，dirty page，flush，buffer pool，double write buffer，change buffer,group commit



Checkpoint（检查点）技术的目的是解决以下几个问题：
❑缩短数据库的恢复时间；崩溃恢复时不必重做所有redo log，只重做从checkpoint开始处的即可。
❑缓冲池不够用时，将脏页刷新到磁盘；老的redo log就可以删除了，checkpoint前移。
❑重做日志不可用时，刷新脏页。老的redo log就可以删除了，因为是环形写入，就又可以继续写了。


LSN：
每个页有LSN，重做日志中也有LSN，Checkpoint也有LSN。
mysql>SHOW ENGINE INNODB STATUS\G;
---
LOG
---
Log sequence number 92561351052
Log flushed up to 92561351052
Last checkpoint at 92561351052



http://dev.mysql.com/doc/refman/5.6/en/innodb-recovery.html

1. prepare ，然后将redo log持久化到磁盘
2. 如果前面prepare成功，那么再继续将事务日志持久化到binlog
3. 如果前面成功，那么在redo log里面写上一个commit记录
那么假如在进行着三步时又任何一步失败，crash recovery是怎么进行的呢? 此时会先从redo log将最近一个检查点开始的事务读出来，
然后参考binlog里面的事务进行恢复。如果是在1 crash，那么自然整个事务都回滚；如果是在2 crash，那么也会整个事务回滚；
如果是在3 crash（仅仅是commit记录没写成功），那么没有关系因为2中已经记录了此次事务的binlog，所以将这个进行commit。
所以总结起来就是redo log里凡是prepare成功，但commit失败的事务都会先去binlog查找判断其是否存在
（通过XID进行判断，是不是经常在binlog里面看到Xid=xxxx？这就是xa事务id），如果有则将这个事务commit，否则rollback

进入XA Recover阶段，MySQL使用内部XA，即通过Binlog和InnoDB做XA恢复。在初始化完成引擎后，Server层会开始扫描最后一个Binlog文件，
搜集其中记录的XID（MYSQL_BIN_LOG::recover），然后和InnoDB层的事务XID做对比。如果XID已经存在于binlog中了，对应的事务需要提交；
否则需要回滚事务。
Tips：为何只需要扫描最后一个binlog文件就可以了？ 因为在每次rotate到一个新的binlog文件之前，总是要保证前一个binlog文件中对应的事务
都提交并且sync redo到磁盘了，也就是说，前一个binlog文件中的事务在崩溃恢复时肯定是出于提交状态的。

在一个事务发出COMMIT动作之前，由于sync_binlog为1，因此会将二进制日志立即写入磁盘。如果这时已经写入了二进制日志，但是提交还没有发生，
并且此时发生了宕机，那么在MySQL数据库下次启动时，由于COMMIT操作并没有发生，这个事务会被回滚掉。但是二进制日志已经记录了该事务信息，
不能被回滚。这个问题可以通过将参数innodb_support_xa设为1来解决，虽然innodb_support_xa与XA事务有关，但它同时也确保了二进制日志和InnoDB
存储引擎数据文件的同步。




有几种场景可能会触发redo log写文件：

Redo log buffer空间不足时
事务提交
后台线程
做checkpoint
实例shutdown时
binlog切换时
我们所熟悉的参数innodb_flush_log_at_trx_commit 作用于事务提交时，这也是最常见的场景：
当设置该值为1时，每次事务提交都要做一次fsync，这是最安全的配置，即使宕机也不会丢失事务；


由于各个事务可以交叉的将事务日志拷贝到log buffer中，因而一次事务提交触发的写redo到文件，可能隐式的帮别的线程“顺便”也写了redo log，
从而达到group commit的效果。

当正常shutdown实例时，会将所有的脏页都刷到磁盘，并做一次完全同步的checkpoint；同时将最后的lsn写到系统表ibdata的第一个page
中（函数fil_write_flushed_lsn）。在重启时，可以根据该lsn来判断这是不是一次正常的shutdown，如果不是就需要去做崩溃恢复逻辑。

在初始化回滚段的时候，我们通过读入回滚段页并进行redo log apply，就可以将回滚段信息恢复到一致的状态，从而能够 “复活”在系统崩溃时
活跃的事务，维护到读写事务链表中。对于处于prepare状态的事务，我们后续需要做额外处理。

当实例从崩溃中恢复时，需要将活跃的事务从undo中提取出来，对于ACTIVE状态的事务直接回滚，对于Prepare状态的事务，如果该事务对应的
binlog已经记录，则提交，否则回滚事务。

http://www.cnblogs.com/chenpingzhao/p/5003881.html




很显然，如果我们弱化配置的持久性(innodb_flush_log_at_trx_commit != 1 或者 sync_binlog != 1)， 宕机可能导致两种丢数据的场景：

引擎层提交了，但binlog没写入，备库丢事务；
引擎层没有prepare，但binlog写入了，主库丢事务。
即使我们将参数设置成innodb_flush_log_at_trx_commit =1 和 sync_binlog = 1，也还会面临这样一种情况：主库crash时还有binlog没传递到备库，如果我们直接提升备库为主库，同样会导致主备不一致，老主库必须根据新主库重做，才能恢复到一致的状态。针对这种场景，我们可以通过开启semisync的方式来解决，一种可行的方案描述如下：

设置双1强持久化配置;
我们将semisync的超时时间设到极大值，同时使用semisync AFTER_SYNC模式，即用户线程在写入binlog后，引擎层提交前等待备库ACK；
基于步骤1的配置，我们可以保证在主库crash时，所有老主库比备库多出来的事务都处于prepare状态；
备库完全apply日志后，记下其执行到的relay log对应的位点，然后将备库提升为新主库；
将老主库的最后一个binlog进行截断，截断的位点即为步骤3记录的位点;
启动老主库，那些已经传递到备库的事务都会提交掉，未传递到备库的binlog都会回滚掉。

-----------------------------------------------------------------------------------------------------------------------
落盘操作：
事务提交，redo log持久化到磁盘
发生checkpoint，刷脏页到磁盘

------------------------------------------------------------------------------------------------------------------
页：

mysql>SELECT TABLE_NAME,SPACE,PAGE_NUMBER,PAGE_TYPE->FROM INNODB_BUFFER_PAGE_LRU->WHERE OLDEST_MODIFICATION>0;
+------------+---+|TABLE_NAME|SPACE|PAGE_NUMBER|PAGE_TYPE|
                  |NULL|0|56|SYSTEM|
                  |NULL|0|0|FILE_SPACE_HEADER|
                  |test/t|1|3|INDEX|
                  |NULL|0|320|INODE|
                  |NULL|0|325|UNDO_LOG|
                  5 rows in set(0.00 sec) 

------------------------------------------------------------------------------------------------------------------------------------
mysql index condition pushdow


MySQL Fabric



GTID

