一致性非锁定读，也叫快照读：（MVCC实现，而MVCC基于undo log）
当session A读取的行正在session B事务内执行DELETE、UPDATE操作时（此时session B 对数据行加了X锁），这时session A的读取操作不会因此等待行上
的锁释放。相反，它会去读取一个数据快照。（而在RR隔离级别下，session B提交了事务，释放了锁后，session A读取的仍是 session A事务开始时的
数据版本。而在RC隔离级别下，sessionB提交了事务，释放了锁后，session A读取的是数据最新版本，是被session B修改后的版本。此时对于session A
来说，是不可重复读）现在相信大家已经理解了我们为什么将它称之为非锁定读，因为不需要等待访问行上X锁的释放。

             Session A              Session B

           SET autocommit=0;      SET autocommit=0;
time
|          SELECT * FROM t;
|          empty set
|                                 INSERT INTO t VALUES (1, 2);
|
v          SELECT * FROM t;
           empty set
                                  COMMIT;

           SELECT * FROM t;
           empty set

           COMMIT;

           SELECT * FROM t;
           ---------------------
           |    1    |    2    |
           ---------------------


innodb在默认情况下的读采取的是一致性非锁定读，但在某些情况下，innodb不采用这种方法。
比如，你在显式对读进行加锁情况下（当前读）
select * from table where ? lock in share mode;(sets an IS lock)
select * from table where ? for update;(sets an IX lock)
或者在外键的插入和更新上，因为在外键的插入更新上，对于数据的隔离性要求较高，在插入前需要扫描父表中的记录是否存在，
所以，innodb在外键添加删除这种操作上，会采用加S锁的这种方式来实现。

rc事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据.（因为read commited嘛，但不可重复读）
RR事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。

快照读只适用于SELECT语句，不适用与DML语句，所以事务中的DML语句（当前读）是可以看到其他session中的事务的更新的，即时SELECT并不能看到这些


快照读：就是select
select * from table ....;
当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。
select * from table where ? lock in share mode;(sets an IS lock)
select * from table where ? for update;(sets an IX lock)
insert;
update ? where ?;
delete ? where ?;
事务的隔离级别实际上都是定义了当前读的级别

--------------------------------------------------------------------------------------------------------------
事务和锁

所谓innodb行锁，是针对有索引的语句，如果语句没有使用上索引，那么就会变成无索引退化，对于当前读就会变成表锁。


对于当前读：
序列化
幻读（如果只有幻读，那么就已经可重复读）
可重复读
不可重复读
脏读


autocommit = 1，使每一个语句都成为一个事务。If a statement returns an error, the commit or rollback behavior depends on the error：
http://dev.mysql.com/doc/refman/5.6/en/innodb-transaction-model.html
autocommit = 0, commit或者rollback后，会自动又开启一个事务，就是说当前session始终有事务打开

自动提交情况下，如果想用多条语句事务，可以使用 start transaction 或者 begin 结束时或者commit或者rollback。
commit和rollback会释放当前session持有的所有锁



事务隔离级别（要从当前事务和其他事务两个角度考虑，而且要有时序图与锁的想象，因为隔离级别通过锁实现）：

SERIALIZABLE        从MVCC退化为基于锁的并发控制。无快照读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。读写互斥。
READ UNCOMMITTED    可读未提交，会脏读，不可重复读，会幻读
READ COMMITTED      未提交不可读，只能读已提交。不会脏读，不可重复读，会幻读
REPEATABLE READ     可重复读，需要用next-key解决幻读
                    REPEATABLE READ, enables higher concurrency by allowing transactions to read rows that have exclusive locks,
                    a technique known as consistent nonlocking read.






锁：
record lock
gap lock
next key lock
行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别的幻读问题。

共享锁  也叫S锁  也叫读锁
排他锁  也叫X锁  也叫写锁
意向锁  包括IS锁与IX锁


    	 X          IX	         S      	   IS
X	  Conflict	Conflict	  Conflict	  Conflict
IX	Conflict	Compatible	Conflict	  Compatible
S	  Conflict	Conflict	  Compatible	Compatible
IS	Conflict	Compatible	Compatible	Compatible


死锁：
innodb_print_all_deadlocks：
When this option is enabled, information about all deadlocks in InnoDB user transactions is recorded in the mysqld error log.
Otherwise, you see information about only the last deadlock, using the SHOW ENGINE INNODB STATUS command. 



-------------------------------------------------------------------------------------------------------
加锁语句：
因为事务一旦完成（commit或者rollback），事务所持有的锁就会释放。
故在autocommit = 1 时，需要注意

select * from table where ? lock in share mode;(sets an IS lock)
select * from table where ? for update;(sets an IX lock)
当autocommit 系统变量值为off 或者为0 时可直接使用不用手动的begin or start transaction开启事务，
如果autocommit为1，需要begin或者start transaction 在使用上述两个语句加锁（因为如果为1，自动提交，事务就结束了，锁就释放了嘛）
表的引擎需要支持事务，比如INNODB。



加表锁：
The correct way to use LOCK TABLES with transactional tables, such as InnoDB tables, is to begin a transaction 
with SET autocommit = 0(not START TRANSACTION) followed by LOCK TABLES, and to not call UNLOCK TABLES until 
you commit the transaction explicitly. 
如下：
SET autocommit=0;
LOCK TABLES t1 WRITE, t2 READ, ...;
... do something with tables t1 and t2 here ...
COMMIT;
UNLOCK TABLES;

加表锁语句：
LOCK TABLES ... WRITE 表写锁
LOCK TABLES ... READ  表读锁

FLUSH TABLES WITH READ LOCK(UNLOCK TABLES 配合使用）



-----------------------------------------------------------------------------------------------------
相关参数
innodb_lock_wait_timeout

---------------------------------------------------------------------------------------------------------
逻辑概念：

undo log   保证事务的原子性（就是说得有一个地方记录回滚的数据），以及用来实现MVCC（因为记录了可以用来回滚的数据，所有数据的历史版本）

redo log   保证事务的持久性（日志先行）




物理文件相关：

ibdata file                              
系统表空间

.ibd file
表独立表空间
.frm
mysql层表定义文件

     
ib_logfile0，ib_logfile1  存有redo log


system tablespace
One or more data files (ibdata files) containing the metadata for InnoDB-related objects (the data dictionary), and the storage areas
for one or more undo logs, the change buffer, and the doublewrite buffer. Depending on the setting of the innodb_file_per_table,
when tables are created, it might also contain table and index data for some or all InnoDB tables. The data and metadata in the 
system tablespace apply to all the databases in a MySQL instance.
Prior to MySQL 5.6.7, the default was to keep all InnoDB tables and indexes inside the system tablespace, often causing this file 
to become very large. Because the system tablespace never shrinks, storage problems could arise if large amounts of temporary data
were loaded and then deleted. In MySQL 5.6.7 and higher, the default is file-per-table mode, where each table and its associated
indexes are stored in a separate .ibd file. This new default makes it easier to use InnoDB features that rely on the Barracuda file 
format, such as table compression, off-page storage for long variable-length column values, and large index key
prefixes (innodb_large_prefix).
Keeping all table data in the system tablespace or in separate .ibd files has implications for storage management in general. 
The MySQL Enterprise Backup product might back up a small set of large files, or many smaller files. On systems with thousands of 
tables, the file system operations to process thousands of .ibd files can cause bottlenecks.
In MySQL 5.6 and higher, the innodb_undo_tablespaces option allows you to configure separate tablespace files for undo logs. 
These files are still considered part of the system tablespace.



data dictionary
Metadata that keeps track of InnoDB-related objects such as tables, indexes, and table columns. This metadata is physically located 
in the InnoDB system tablespace. For historical reasons, it overlaps to some degree with information stored in the .frm files.


--------------------------------------------------------------------------------------------------------------------
代码细节：
进入XA Recover阶段，MySQL使用内部XA，即通过Binlog和InnoDB做XA恢复。在初始化完成引擎后，Server层会开始扫描最后一个Binlog文件，
搜集其中记录的XID（MYSQL_BIN_LOG::recover），然后和InnoDB层的事务XID做对比。如果XID已经存在于binlog中了，对应的事务需要提交；
否则需要回滚事务。
Tips：为何只需要扫描最后一个binlog文件就可以了？ 因为在每次rotate到一个新的binlog文件之前，总是要保证前一个binlog文件中对应的事务
都提交并且sync redo到磁盘了，也就是说，前一个binlog文件中的事务在崩溃恢复时肯定是出于提交状态的。


有几种场景可能会触发redo log写文件：

Redo log buffer空间不足时
事务提交
后台线程
做checkpoint
实例shutdown时
binlog切换时
我们所熟悉的参数innodb_flush_log_at_trx_commit 作用于事务提交时，这也是最常见的场景：
当设置该值为1时，每次事务提交都要做一次fsync，这是最安全的配置，即使宕机也不会丢失事务；


由于各个事务可以交叉的将事务日志拷贝到log buffer中，因而一次事务提交触发的写redo到文件，可能隐式的帮别的线程“顺便”也写了redo log，
从而达到group commit的效果。

当正常shutdown实例时，会将所有的脏页都刷到磁盘，并做一次完全同步的checkpoint；同时将最后的lsn写到系统表ibdata的第一个page
中（函数fil_write_flushed_lsn）。在重启时，可以根据该lsn来判断这是不是一次正常的shutdown，如果不是就需要去做崩溃恢复逻辑。

在初始化回滚段的时候，我们通过读入回滚段页并进行redo log apply，就可以将回滚段信息恢复到一致的状态，从而能够 “复活”在系统崩溃时
活跃的事务，维护到读写事务链表中。对于处于prepare状态的事务，我们后续需要做额外处理。

当实例从崩溃中恢复时，需要将活跃的事务从undo中提取出来，对于ACTIVE状态的事务直接回滚，对于Prepare状态的事务，如果该事务对应的
binlog已经记录，则提交，否则回滚事务。

http://www.cnblogs.com/chenpingzhao/p/5003881.html




很显然，如果我们弱化配置的持久性(innodb_flush_log_at_trx_commit != 1 或者 sync_binlog != 1)， 宕机可能导致两种丢数据的场景：

引擎层提交了，但binlog没写入，备库丢事务；
引擎层没有prepare，但binlog写入了，主库丢事务。
即使我们将参数设置成innodb_flush_log_at_trx_commit =1 和 sync_binlog = 1，也还会面临这样一种情况：主库crash时还有binlog没传递到备库，如果我们直接提升备库为主库，同样会导致主备不一致，老主库必须根据新主库重做，才能恢复到一致的状态。针对这种场景，我们可以通过开启semisync的方式来解决，一种可行的方案描述如下：

设置双1强持久化配置;
我们将semisync的超时时间设到极大值，同时使用semisync AFTER_SYNC模式，即用户线程在写入binlog后，引擎层提交前等待备库ACK；
基于步骤1的配置，我们可以保证在主库crash时，所有老主库比备库多出来的事务都处于prepare状态；
备库完全apply日志后，记下其执行到的relay log对应的位点，然后将备库提升为新主库；
将老主库的最后一个binlog进行截断，截断的位点即为步骤3记录的位点;
启动老主库，那些已经传递到备库的事务都会提交掉，未传递到备库的binlog都会回滚掉。

-----------------------------------------------------------------------------------------------------------------------

mysql index condition pushdow


MySQL Fabric



GTID

